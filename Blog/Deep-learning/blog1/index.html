<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>sentimentanalysislayer_LSTM | JJBlog</title>
    <meta name="generator" content="VuePress 1.9.9">
    
    <meta name="description" content="前端、前端教程、小程序、个人博客、张晶晶博客">
    
    <link rel="preload" href="/Blog/assets/css/0.styles.d75286d0.css" as="style"><link rel="preload" href="/Blog/assets/js/app.05fbaaaf.js" as="script"><link rel="preload" href="/Blog/assets/js/2.733019b2.js" as="script"><link rel="preload" href="/Blog/assets/js/8.d35a637b.js" as="script"><link rel="prefetch" href="/Blog/assets/js/10.1c5858b8.js"><link rel="prefetch" href="/Blog/assets/js/11.420206ab.js"><link rel="prefetch" href="/Blog/assets/js/12.a3bf6056.js"><link rel="prefetch" href="/Blog/assets/js/13.5eef12c0.js"><link rel="prefetch" href="/Blog/assets/js/14.7258a101.js"><link rel="prefetch" href="/Blog/assets/js/15.67377551.js"><link rel="prefetch" href="/Blog/assets/js/16.71e5bca4.js"><link rel="prefetch" href="/Blog/assets/js/17.f50924dd.js"><link rel="prefetch" href="/Blog/assets/js/18.a322b80b.js"><link rel="prefetch" href="/Blog/assets/js/19.fe304b8b.js"><link rel="prefetch" href="/Blog/assets/js/20.cabf7c8f.js"><link rel="prefetch" href="/Blog/assets/js/21.65ef7b2a.js"><link rel="prefetch" href="/Blog/assets/js/22.3d5b2a52.js"><link rel="prefetch" href="/Blog/assets/js/23.df34116e.js"><link rel="prefetch" href="/Blog/assets/js/24.553098af.js"><link rel="prefetch" href="/Blog/assets/js/25.3fd7cb0b.js"><link rel="prefetch" href="/Blog/assets/js/26.1d6b4bd9.js"><link rel="prefetch" href="/Blog/assets/js/27.d0638a89.js"><link rel="prefetch" href="/Blog/assets/js/28.9a1d0826.js"><link rel="prefetch" href="/Blog/assets/js/29.956607b5.js"><link rel="prefetch" href="/Blog/assets/js/3.96557567.js"><link rel="prefetch" href="/Blog/assets/js/30.fde4c090.js"><link rel="prefetch" href="/Blog/assets/js/31.54a22f0c.js"><link rel="prefetch" href="/Blog/assets/js/32.2c3a28dc.js"><link rel="prefetch" href="/Blog/assets/js/33.73f4bbc5.js"><link rel="prefetch" href="/Blog/assets/js/34.186ec671.js"><link rel="prefetch" href="/Blog/assets/js/35.078c8411.js"><link rel="prefetch" href="/Blog/assets/js/36.3afaaebf.js"><link rel="prefetch" href="/Blog/assets/js/37.a3f916b3.js"><link rel="prefetch" href="/Blog/assets/js/4.d12742be.js"><link rel="prefetch" href="/Blog/assets/js/5.216cae74.js"><link rel="prefetch" href="/Blog/assets/js/6.2d0a63f8.js"><link rel="prefetch" href="/Blog/assets/js/7.69e75d2d.js"><link rel="prefetch" href="/Blog/assets/js/9.2fe8d97f.js">
    <link rel="stylesheet" href="/Blog/assets/css/0.styles.d75286d0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/Blog/" class="home-link router-link-active"><!----> <span class="site-name">JJBlog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/Blog/Resume/myResume/" class="nav-link">
  Resume
</a></div><div class="nav-item"><a href="/Blog/Blog/" class="nav-link router-link-active">
  Blogs
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Menu" class="dropdown-title"><span class="title">Others</span> <span class="arrow down"></span></button> <button type="button" aria-label="Menu" class="mobile-dropdown-title"><span class="title">Others</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/Blog/other/contact/" class="nav-link">
  与我联系
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/Xiaojing-511?tab=repositories" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/Blog/Resume/myResume/" class="nav-link">
  Resume
</a></div><div class="nav-item"><a href="/Blog/Blog/" class="nav-link router-link-active">
  Blogs
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Menu" class="dropdown-title"><span class="title">Others</span> <span class="arrow down"></span></button> <button type="button" aria-label="Menu" class="mobile-dropdown-title"><span class="title">Others</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/Blog/other/contact/" class="nav-link">
  与我联系
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/Xiaojing-511?tab=repositories" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Resume/myResume/" class="sidebar-heading clickable"><span>Resume</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Projects/hokdo/" class="sidebar-heading clickable"><span>Projects</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Blog/" class="sidebar-heading clickable router-link-active open"><span>Blogs</span> <span class="arrow down"></span></a> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Web/blog1/" class="sidebar-heading clickable"><span>Web</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Ant/blog1/" class="sidebar-heading clickable"><span>Ant Design Vue</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Deep-learning/blog1/" aria-current="page" class="sidebar-heading clickable router-link-exact-active router-link-active open active"><span>Deep learning</span> <span class="arrow down"></span></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/Blog/Blog/Deep-learning/blog1/" aria-current="page" class="active sidebar-link">使用LSTM进行情感分析</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/Blog/Blog/Deep-learning/blog1/#sentiment-analysis-layer-lstm" class="sidebar-link">sentimentanalysislayer_LSTM</a></li><li class="sidebar-sub-header"><a href="/Blog/Blog/Deep-learning/blog1/#了解更多" class="sidebar-link">了解更多：</a></li><li class="sidebar-sub-header"><a href="/Blog/Blog/Deep-learning/blog1/#附录-源代码" class="sidebar-link">附录（源代码）</a></li></ul></li><li><a href="/Blog/Blog/Deep-learning/blog2/" class="sidebar-link">手写体数字识别(Hand-written digits recognition)</a></li><li><a href="/Blog/Blog/Deep-learning/blog3/" class="sidebar-link">Tensorflow 2.0 利用十三层卷积神经网络实现cifar 100训练</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Others/blog1/" class="sidebar-heading clickable"><span>Others</span> <span class="arrow right"></span></a> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Notes/note1/" class="sidebar-heading clickable"><span>Notes</span> <span class="arrow right"></span></a> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="sentiment-analysis-layer-lstm"><a href="#sentiment-analysis-layer-lstm" class="header-anchor">#</a> sentiment_analysis_layer_LSTM</h2> <blockquote><p>2020-9-10 13:27:19
<br>分类专栏：深度学习 神经网络 LSTM</p></blockquote> <p>我们来利用基础的 RNN 网络来挑战情感分类问题。RNN 网络共 2 层，循环提取序列信号的语义特征，利用第 2 层 RNN 层的最后时间戳的状态向量作为句子的特征表示，送入全连接层构成的分类网络 3，得到样本为积极情感的概率P(x 为积极情感| ) ∈ [0,1]。</p> <blockquote><p>IMDB 影评数据集包含了 50,000 条用户评价，评价的标签分为消极和积极， 其中IMDB 评级&lt;5 的用户评价标注为 0，即消极； IMDB 评价&gt;=7 的用户评价标注为 1，即积极。 25,000 条影评用于训练集， 25,000 条用于测试集。可以通过keras.datasets直接加载。</p></blockquote> <p>一个序列（句子）在每个时间戳上面产生的是一个单词或字符。如果希望神经网络能够用于自然语言处理任务，那么怎么把单词或字符转化为向量就尤为关键。在神经网络中，单词的表示向量可以直接通过训练的方式得到，我们把单词的表示层叫做 Embedding 层。 Embedding 层负责把单词编码为某个向量 ，他接受的是采用数字编码的单词 ，如 2 表示“ I”， 3 表示“ me” 等， 系统总单词数量记为 _ ， 输出长度为f的向量 。在 TensorFlow 中，可以通过 layers.Embedding( _ , )来定义一 Word Embedding层，其中 _ 参数指定词汇数量， 指定单词向量的长度。</p> <p>在每个时间戳，网络层接受当前时间戳的输入  和上一个时间戳的网络状态向量  ，经过  运算后得到当前时间戳的新状态向量  ,并写入内存状态中。在每个时间戳上，网络层均有输出产生  ，即将网络的状态向量变换后输出。</p> <p>长短期记忆单元是你可以放置在神经中枢的模块。在较高的层次上，它们确保隐藏状态向量h能够在文本中封装关于长期依赖关系的信息。在 LSTM 中，有两个状态向量c和h， 其中c作为 LSTM 的内部状态向量，可以理解为LSTM 的内存 Memory，而h表示 LSTM 的输出向量，相对于基础的 RNN 来说， LSTM 把内部 Memory 和输出分开为 2 个变量，同时利用三个门控：输入门(Input Gate)， 遗忘门(Forget Gate)和输出门(Output Gate)来控制内部信息的流动。
<img src="https://img-blog.csdnimg.cn/2020112019541831.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="遗忘门"> <img src="https://img-blog.csdnimg.cn/20201120195455238.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"> <img src="https://img-blog.csdnimg.cn/20201120195509859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"> <img src="https://img-blog.csdnimg.cn/20201120195521348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"> <img src="https://img-blog.csdnimg.cn/20201120195621497.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">
用来测试的数据是一段阿甘正传的影评 ，</p> <blockquote><p>Forrest Gump, the movie which I have watched for three times, is a film that surprised and moved me so much .It was based on the novel of Winston Groom while the hero is a famous actor—Tom Hanks. He performed so well all through the film that I enjoyed the warm human nature, the inspiration of belief and other virtues through any scene in it.</p></blockquote> <p>训练及测试的截图如下（因为训练时间有点无法忍受所以只循环训练了20几次）</p> <p>epoch=10时，
<img src="https://img-blog.csdnimg.cn/20201120194727761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">
epoch=28时，
<img src="https://img-blog.csdnimg.cn/20201120194846782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">
将一维数组转化为二维满足IMDB格式的词数字编码后再预测
<img src="https://img-blog.csdnimg.cn/20201120194905845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">
测试出影评为正向好评的概率是0.73，差评概率为0.27，训练的模型还算可以但是因为训练的次数还是太少，所以效果不是太理想。</p> <h2 id="了解更多"><a href="#了解更多" class="header-anchor">#</a> 了解更多：</h2> <p>相对于基本RNN网络只有一个状态向量  ，LSTM 新增了一个状态向量  ，同时引入了门控(Gate)机制， 通过门控来控制信息的遗忘和刷新。</p> <p>LSTM的变种-GRU
LSTM 具有更长的记忆能力， 在大部分序列任务上面都取得了比基础的 RNN 模型更好的性能表现，更重要的是， LSTM 不容易出现梯度弥散现象。 但是 LSTM 相对较复杂， 计算代价较高，模型参数量较大。 于是科学家们尝试简化 LSTM 内部的计算流程， 特别是减少门控数量。 研究发现， 遗忘门是 LSTM 中最重要的门控 (Westhuizen &amp; Lasenby, 2018)，甚至发现只有遗忘门的简化版网络在多个基准数据集上面优于标准 LSTM 网络。 在众多的简化版 LSTM 中，门控循环网络(Gated Recurrent Unit)是应用最广泛的变种之一。 GRU 把内部状态向量和输出向量合并，统一为状态向量 ， 门控数量也减少到 2 个：复位门(ResetGate)和更新门(Update Gate)。</p> <h2 id="附录-源代码"><a href="#附录-源代码" class="header-anchor">#</a> 附录（源代码）</h2> <p>带有测试及对感情词汇频率的排序</p> <div class="language-cpp extra-class"><pre class="language-cpp"><code><span class="token keyword">import</span>  <span class="token module">os</span>
<span class="token keyword">import</span> <span class="token module">sys</span>
<span class="token keyword">import</span> <span class="token module">re</span><span class="token punctuation">,</span>string
<span class="token keyword">import</span>  <span class="token module">tensorflow</span> as tf
<span class="token keyword">import</span>  <span class="token module">numpy</span> as np
from    tensorflow <span class="token keyword">import</span> <span class="token module">keras</span>
from    tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> <span class="token module">layers</span><span class="token punctuation">,</span> losses<span class="token punctuation">,</span> optimizers<span class="token punctuation">,</span> Sequential

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token char">'TF_CPP_MIN_LOG_LEVEL'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token char">'2'</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token char">'0'</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">&quot;This code run on the GPU ID:&quot;</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token char">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">gpus</span> <span class="token expression"><span class="token operator">=</span> tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span><span class="token function">list_physical_devices</span><span class="token punctuation">(</span>device_type<span class="token operator">=</span></span><span class="token char">'GPU'</span><span class="token expression"><span class="token punctuation">)</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">gpus</span> <span class="token expression"><span class="token operator">=</span> tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span><span class="token function">list_physical_devices</span><span class="token punctuation">(</span>device_type<span class="token operator">=</span>None<span class="token punctuation">)</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">for</span> <span class="token expression">gpu in gpus<span class="token operator">:</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span>     <span class="token directive keyword">tf</span><span class="token expression"><span class="token punctuation">.</span>config<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span><span class="token function">set_memory_growth</span><span class="token punctuation">(</span>gpu<span class="token punctuation">,</span> True<span class="token punctuation">)</span></span></span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">assert</span> <span class="token expression">tf<span class="token punctuation">.</span>__version__<span class="token punctuation">.</span><span class="token function">startswith</span><span class="token punctuation">(</span></span><span class="token char">'2.'</span><span class="token expression"><span class="token punctuation">)</span></span></span>

tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">set_seed</span><span class="token punctuation">(</span><span class="token number">22</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">seed</span><span class="token punctuation">(</span><span class="token number">22</span><span class="token punctuation">)</span>

batchsz <span class="token operator">=</span> <span class="token number">128</span> # 批量大小
total_words <span class="token operator">=</span> <span class="token number">10000</span> # 词汇表大小N_vocab（词汇表中的词是按照词使用的频率由小到大排列的，这里之关系前<span class="token number">10000</span>个常用词）
max_review_len <span class="token operator">=</span> <span class="token number">80</span> # 句子最大长度s，大于的句子部分将截断，小于的将填充
embedding_len <span class="token operator">=</span> <span class="token number">100</span> # 词向量特征长度f
# 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>imdb<span class="token punctuation">.</span><span class="token function">load_data</span><span class="token punctuation">(</span>num_words<span class="token operator">=</span>total_words<span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">print</span><span class="token expression"><span class="token punctuation">(</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>x_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">print</span><span class="token expression"><span class="token punctuation">(</span>x_test<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>x_test<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span></span>
#<span class="token operator">%</span><span class="token operator">%</span>输出第一个影评的词向量数字编码
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">print</span><span class="token expression"><span class="token punctuation">(</span></span><span class="token string">&quot;This is the first sample in training data:&quot;</span><span class="token expression"><span class="token punctuation">,</span> x_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span></span>
# 利用等待键盘输入的方式暂停一下，让你观察一下text形式的数据
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">input</span><span class="token expression"><span class="token punctuation">(</span><span class="token punctuation">)</span></span></span>
#<span class="token operator">%</span><span class="token operator">%</span>
# 数字编码表<span class="token punctuation">(</span>这是IMDB数据集自带的词编码表<span class="token punctuation">)</span>
word_index <span class="token operator">=</span> keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>imdb<span class="token punctuation">.</span><span class="token function">get_word_index</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
#输出词数字编码表
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">for</span> <span class="token expression">k<span class="token punctuation">,</span>v in word_index<span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span>      <span class="token directive keyword">print</span><span class="token expression"><span class="token punctuation">(</span>k<span class="token punctuation">,</span>v<span class="token punctuation">)</span></span></span>

word_dict <span class="token operator">=</span> <span class="token function">sorted</span><span class="token punctuation">(</span>word_index<span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span>lambda d<span class="token operator">:</span>d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i in word_dict<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">1500</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


#<span class="token operator">%</span><span class="token operator">%</span>在IMDB数据预处理的过程中，前<span class="token number">4</span>个value：<span class="token number">0</span>，<span class="token number">1</span>，<span class="token number">2</span>，<span class="token number">3</span>分别作为padding<span class="token operator">-</span><span class="token number">0</span>，start<span class="token operator">-</span><span class="token number">1</span>，unknown<span class="token operator">-</span><span class="token number">2</span>和unused<span class="token operator">-</span><span class="token number">3</span>的标记，
#所以要在IMDB原始词编码表的基础上，将value<span class="token operator">+</span><span class="token number">3</span>后才能得到IMDB data
word_index <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token operator">:</span><span class="token punctuation">(</span>v<span class="token operator">+</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span>v in word_index<span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
word_index<span class="token punctuation">[</span><span class="token string">&quot;&lt;PAD&gt;&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
word_index<span class="token punctuation">[</span><span class="token string">&quot;&lt;START&gt;&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
word_index<span class="token punctuation">[</span><span class="token string">&quot;&lt;UNK&gt;&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span>  # unknown
word_index<span class="token punctuation">[</span><span class="token string">&quot;&lt;UNUSED&gt;&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">3</span>

# 翻转编码表（可以利用它将词向量表转化为自然语言的句子，当然这里面不包含标点符号）
reverse_word_index <span class="token operator">=</span> <span class="token function">dict</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> key<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> in word_index<span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
# 利用翻转编码表将词向量转化为text向量
def <span class="token function">decode_review</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token keyword">return</span> <span class="token char">' '</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">[</span>reverse_word_index<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token char">'?'</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i in text<span class="token punctuation">]</span><span class="token punctuation">)</span>
# 利用<span class="token function">decode_review</span><span class="token punctuation">(</span><span class="token punctuation">)</span>将训练数据x_train<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span>转化为text，请阅读输出结果
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">print</span><span class="token expression"><span class="token punctuation">(</span><span class="token function">decode_review</span><span class="token punctuation">(</span>x_train<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span></span>
# 利用等待键盘输入的方式暂停一下，让你观察一下text形式的数据
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">input</span><span class="token expression"><span class="token punctuation">(</span><span class="token punctuation">)</span></span></span>
#<span class="token operator">%</span><span class="token operator">%</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">x</span><span class="token expression">_train<span class="token operator">:</span><span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">x</span><span class="token expression">_test<span class="token operator">:</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span></span></span>
# 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充
x_train <span class="token operator">=</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence<span class="token punctuation">.</span><span class="token function">pad_sequences</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_review_len<span class="token punctuation">)</span>
x_test <span class="token operator">=</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence<span class="token punctuation">.</span><span class="token function">pad_sequences</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_review_len<span class="token punctuation">)</span>
# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch
db_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span><span class="token function">from_tensor_slices</span><span class="token punctuation">(</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
db_train <span class="token operator">=</span> db_train<span class="token punctuation">.</span><span class="token function">shuffle</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">batch</span><span class="token punctuation">(</span>batchsz<span class="token punctuation">,</span> drop_remainder<span class="token operator">=</span>True<span class="token punctuation">)</span>
db_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span><span class="token function">from_tensor_slices</span><span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
db_test <span class="token operator">=</span> db_test<span class="token punctuation">.</span><span class="token function">batch</span><span class="token punctuation">(</span>batchsz<span class="token punctuation">,</span> drop_remainder<span class="token operator">=</span>True<span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">print</span><span class="token expression"><span class="token punctuation">(</span></span><span class="token char">'x_train shape:'</span><span class="token expression"><span class="token punctuation">,</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> tf<span class="token punctuation">.</span><span class="token function">reduce_max</span><span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span><span class="token function">reduce_min</span><span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">)</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">print</span><span class="token expression"><span class="token punctuation">(</span></span><span class="token char">'x_test shape:'</span><span class="token expression"><span class="token punctuation">,</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span></span>

#<span class="token operator">%</span><span class="token operator">%</span>

<span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Cell方式构建多层网络</span></span>
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> units<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token function">super</span><span class="token punctuation">(</span>MyRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 
        # 词向量编码 <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span>
        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">embedding</span><span class="token expression">：单词的表示层 把单词编码为某个向量 ，他接受的是采用数字编码的单词</span></span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> layers<span class="token punctuation">.</span><span class="token function">Embedding</span><span class="token punctuation">(</span>total_words<span class="token punctuation">,</span> embedding_len<span class="token punctuation">,</span>  # 指定词汇数量， 指定单词向量的长度
                                          input_length<span class="token operator">=</span>max_review_len<span class="token punctuation">)</span>
        # 构建RNN  长短时记忆网络LSTM
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> keras<span class="token punctuation">.</span><span class="token function">Sequential</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
            layers<span class="token punctuation">.</span><span class="token function">LSTM</span><span class="token punctuation">(</span>units<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span>True<span class="token punctuation">)</span><span class="token punctuation">,</span>  #默认只会返回最后一个时间戳的输出 返回每个时间戳上面的输出， 需要设置 return_sequences<span class="token operator">=</span>True 标志
            layers<span class="token punctuation">.</span><span class="token function">LSTM</span><span class="token punctuation">(</span>units<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>
        # 构建分类网络，用于将CELL的输出特征进行分类，<span class="token number">2</span>分类
        # <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>outlayer <span class="token operator">=</span> <span class="token function">Sequential</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
        	layers<span class="token punctuation">.</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        	layers<span class="token punctuation">.</span><span class="token function">Dropout</span><span class="token punctuation">(</span>rate<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        	layers<span class="token punctuation">.</span><span class="token function">ReLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        	layers<span class="token punctuation">.</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    def <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> training<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token operator">:</span>
        x <span class="token operator">=</span> inputs # <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span>
        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">embedding</span><span class="token expression"><span class="token operator">:</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span></span></span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">embedding</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">rnn</span> <span class="token expression">cell compute<span class="token punctuation">,</span><span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span></span></span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">rnn</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        # 末层最后一个输出作为分类网络的输入<span class="token operator">:</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">outlayer</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>training<span class="token punctuation">)</span>
        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">p</span><span class="token expression"><span class="token punctuation">(</span>y is pos<span class="token operator">|</span>x<span class="token punctuation">)</span></span></span>
        prob <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> prob

def <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    units <span class="token operator">=</span> <span class="token number">64</span> # RNN状态向量长度f
    epochs <span class="token operator">=</span> <span class="token number">5</span> # 训练epochs

    model <span class="token operator">=</span> <span class="token function">MyRNN</span><span class="token punctuation">(</span>units<span class="token punctuation">)</span>
    # 装配
    model<span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span>optimizer <span class="token operator">=</span> optimizers<span class="token punctuation">.</span><span class="token function">Adam</span><span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  loss <span class="token operator">=</span> losses<span class="token punctuation">.</span><span class="token function">BinaryCrossentropy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token char">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    # 训练和验证
    model<span class="token punctuation">.</span><span class="token function">fit</span><span class="token punctuation">(</span>db_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span>epochs<span class="token punctuation">,</span> validation_data<span class="token operator">=</span>db_test<span class="token punctuation">)</span>
    # 测试
    model<span class="token punctuation">.</span><span class="token function">evaluate</span><span class="token punctuation">(</span>db_test<span class="token punctuation">)</span>

    vector_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    vector_list<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    s <span class="token operator">=</span> <span class="token function">open</span><span class="token punctuation">(</span><span class="token string">&quot;forrest gump.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    punc <span class="token operator">=</span> '<span class="token operator">~</span>`<span class="token operator">!</span>#$<span class="token operator">%</span><span class="token operator">^</span><span class="token operator">&amp;</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">)</span>_<span class="token operator">+</span><span class="token operator">-=</span><span class="token operator">|</span>\'<span class="token punctuation">;</span>&quot;<span class="token operator">:</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token operator">?</span><span class="token operator">&gt;</span><span class="token operator">&lt;</span><span class="token operator">~</span>·！@#￥<span class="token operator">%</span>……<span class="token operator">&amp;</span><span class="token operator">*</span>（）——<span class="token operator">+</span><span class="token operator">-=</span>“：’；、。，？》《<span class="token punctuation">{</span><span class="token punctuation">}</span>'
    word_list <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token function">sub</span><span class="token punctuation">(</span>r<span class="token string">&quot;[%s]+&quot;</span> <span class="token operator">%</span> punc<span class="token punctuation">,</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">if</span> word_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span> in word_index<span class="token punctuation">.</span><span class="token function">keys</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
            vector_list<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>word_index<span class="token punctuation">[</span>word_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token operator">:</span>
            vector_list<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

    <span class="token function">print</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span>
    vector_list <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span>
    vector_list <span class="token operator">=</span> vector_list<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> vector_list<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token function">print</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span>
    <span class="token function">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    vector_list <span class="token operator">=</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence<span class="token punctuation">.</span><span class="token function">pad_sequences</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_review_len<span class="token punctuation">)</span>

    <span class="token function">print</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span>
    <span class="token function">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    vector_list <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">convert_to_tensor</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>

    <span class="token function">print</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span>
    <span class="token function">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    vector_list <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token function">print</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span>
    <span class="token function">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    y <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token function">predict</span><span class="token punctuation">(</span>vector_list<span class="token punctuation">)</span> 
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">input</span><span class="token expression"><span class="token punctuation">(</span><span class="token punctuation">)</span></span></span>
    n <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">sigmoid</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">numpy</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">&quot;The predict of the film review is %.2f to be positive and %.2f to be negative&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token char">'__main__'</span><span class="token operator">:</span>
    <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/Blog/Blog/Ant/blog1/" class="prev">
        树选择组件选择框一行显示不换行
      </a></span> <span class="next"><a href="/Blog/Blog/Deep-learning/blog2/">
        手写体数字识别(Hand-written digits recognition)
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/Blog/assets/js/app.05fbaaaf.js" defer></script><script src="/Blog/assets/js/2.733019b2.js" defer></script><script src="/Blog/assets/js/8.d35a637b.js" defer></script>
  </body>
</html>
