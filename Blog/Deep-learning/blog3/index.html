<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Tensorflow 2.0 利用十三层卷积神经网络实现cifar 100训练（理论+实战） | JJBlog</title>
    <meta name="generator" content="VuePress 1.9.9">
    
    <meta name="description" content="前端、前端教程、小程序、个人博客、张晶晶博客">
    
    <link rel="preload" href="/Blog/assets/css/0.styles.d75286d0.css" as="style"><link rel="preload" href="/Blog/assets/js/app.05fbaaaf.js" as="script"><link rel="preload" href="/Blog/assets/js/2.733019b2.js" as="script"><link rel="preload" href="/Blog/assets/js/10.1c5858b8.js" as="script"><link rel="prefetch" href="/Blog/assets/js/11.420206ab.js"><link rel="prefetch" href="/Blog/assets/js/12.a3bf6056.js"><link rel="prefetch" href="/Blog/assets/js/13.5eef12c0.js"><link rel="prefetch" href="/Blog/assets/js/14.7258a101.js"><link rel="prefetch" href="/Blog/assets/js/15.67377551.js"><link rel="prefetch" href="/Blog/assets/js/16.71e5bca4.js"><link rel="prefetch" href="/Blog/assets/js/17.f50924dd.js"><link rel="prefetch" href="/Blog/assets/js/18.a322b80b.js"><link rel="prefetch" href="/Blog/assets/js/19.fe304b8b.js"><link rel="prefetch" href="/Blog/assets/js/20.cabf7c8f.js"><link rel="prefetch" href="/Blog/assets/js/21.65ef7b2a.js"><link rel="prefetch" href="/Blog/assets/js/22.3d5b2a52.js"><link rel="prefetch" href="/Blog/assets/js/23.df34116e.js"><link rel="prefetch" href="/Blog/assets/js/24.553098af.js"><link rel="prefetch" href="/Blog/assets/js/25.3fd7cb0b.js"><link rel="prefetch" href="/Blog/assets/js/26.1d6b4bd9.js"><link rel="prefetch" href="/Blog/assets/js/27.d0638a89.js"><link rel="prefetch" href="/Blog/assets/js/28.9a1d0826.js"><link rel="prefetch" href="/Blog/assets/js/29.956607b5.js"><link rel="prefetch" href="/Blog/assets/js/3.96557567.js"><link rel="prefetch" href="/Blog/assets/js/30.fde4c090.js"><link rel="prefetch" href="/Blog/assets/js/31.54a22f0c.js"><link rel="prefetch" href="/Blog/assets/js/32.2c3a28dc.js"><link rel="prefetch" href="/Blog/assets/js/33.73f4bbc5.js"><link rel="prefetch" href="/Blog/assets/js/34.186ec671.js"><link rel="prefetch" href="/Blog/assets/js/35.078c8411.js"><link rel="prefetch" href="/Blog/assets/js/36.3afaaebf.js"><link rel="prefetch" href="/Blog/assets/js/37.a3f916b3.js"><link rel="prefetch" href="/Blog/assets/js/4.d12742be.js"><link rel="prefetch" href="/Blog/assets/js/5.216cae74.js"><link rel="prefetch" href="/Blog/assets/js/6.2d0a63f8.js"><link rel="prefetch" href="/Blog/assets/js/7.69e75d2d.js"><link rel="prefetch" href="/Blog/assets/js/8.d35a637b.js"><link rel="prefetch" href="/Blog/assets/js/9.2fe8d97f.js">
    <link rel="stylesheet" href="/Blog/assets/css/0.styles.d75286d0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/Blog/" class="home-link router-link-active"><!----> <span class="site-name">JJBlog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/Blog/Resume/myResume/" class="nav-link">
  Resume
</a></div><div class="nav-item"><a href="/Blog/Blog/" class="nav-link router-link-active">
  Blogs
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Menu" class="dropdown-title"><span class="title">Others</span> <span class="arrow down"></span></button> <button type="button" aria-label="Menu" class="mobile-dropdown-title"><span class="title">Others</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/Blog/other/contact/" class="nav-link">
  与我联系
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/Xiaojing-511?tab=repositories" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/Blog/Resume/myResume/" class="nav-link">
  Resume
</a></div><div class="nav-item"><a href="/Blog/Blog/" class="nav-link router-link-active">
  Blogs
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Menu" class="dropdown-title"><span class="title">Others</span> <span class="arrow down"></span></button> <button type="button" aria-label="Menu" class="mobile-dropdown-title"><span class="title">Others</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/Blog/other/contact/" class="nav-link">
  与我联系
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/Xiaojing-511?tab=repositories" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Resume/myResume/" class="sidebar-heading clickable"><span>Resume</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Projects/hokdo/" class="sidebar-heading clickable"><span>Projects</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Blog/" class="sidebar-heading clickable router-link-active open"><span>Blogs</span> <span class="arrow down"></span></a> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Web/blog1/" class="sidebar-heading clickable"><span>Web</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Ant/blog1/" class="sidebar-heading clickable"><span>Ant Design Vue</span> <span class="arrow right"></span></a> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Deep-learning/blog1/" class="sidebar-heading clickable open"><span>Deep learning</span> <span class="arrow down"></span></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/Blog/Blog/Deep-learning/blog1/" class="sidebar-link">使用LSTM进行情感分析</a></li><li><a href="/Blog/Blog/Deep-learning/blog2/" class="sidebar-link">手写体数字识别(Hand-written digits recognition)</a></li><li><a href="/Blog/Blog/Deep-learning/blog3/" aria-current="page" class="active sidebar-link">Tensorflow 2.0 利用十三层卷积神经网络实现cifar 100训练</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/Blog/Blog/Deep-learning/blog3/#tensorflow-2-0-利用十三层卷积神经网络实现cifar-100训练-理论-实战" class="sidebar-link">Tensorflow 2.0 利用十三层卷积神经网络实现cifar 100训练（理论+实战）</a></li><li class="sidebar-sub-header"><a href="/Blog/Blog/Deep-learning/blog3/#主要思路" class="sidebar-link">主要思路</a></li><li class="sidebar-sub-header"><a href="/Blog/Blog/Deep-learning/blog3/#附录-源代码" class="sidebar-link">附录（源代码）</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/Blog/Blog/Others/blog1/" class="sidebar-heading clickable"><span>Others</span> <span class="arrow right"></span></a> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><a href="/Blog/Notes/note1/" class="sidebar-heading clickable"><span>Notes</span> <span class="arrow right"></span></a> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="tensorflow-2-0-利用十三层卷积神经网络实现cifar-100训练-理论-实战"><a href="#tensorflow-2-0-利用十三层卷积神经网络实现cifar-100训练-理论-实战" class="header-anchor">#</a> Tensorflow 2.0 利用十三层卷积神经网络实现cifar 100训练（理论+实战）</h2> <blockquote><p>2020-9-27 21:29:11
<br>分类专栏：深度学习 VGG13 tensorflow</p></blockquote> <p>VGG模型是2014年ILSVRC竞赛的第二名，第一名是GoogLeNet。但是VGG模型在多个迁移学习任务中的表现要优于googLeNet。而且，从图像中提取CNN特征，VGG模型是首选算法。“VGG”代表了牛津大学的Oxford Visual Geometry Group</p> <h2 id="主要思路"><a href="#主要思路" class="header-anchor">#</a> 主要思路</h2> <p>网络模型是由10层卷积层结合3层全连接层构成，我们通过卷积获取特征后通过max-pooling池化方法减少FeatureMap中不重要的样本，把原图模糊缩减至原来的1/4（根据池化核的尺寸和移动步长计算），再用全连接层把所有卷积得到的特征整合到一起（把这些局部特征进行随机组合，我们就可以输出很多奇奇怪怪的组合图片，只要全连接层够大，我们就一定能得到一张组合图片的样子最接近原图像）通过循环的卷积池化和全连接输出计算loss更新梯度，测试集使用softmax计算各类的概率并选出最大概率作为预测值来计算准确率。</p> <blockquote><p>输入数据集cifar 10数据集中的标签只有10类，而cifar 100数据集对每一类又划分成了10小类，总共有100个类别，每个类600张图片，总共有60000张图片。其中50000张是训练集，10000张作为测试集32 * 32尺寸。</p></blockquote> <p><img src="https://img-blog.csdnimg.cn/20201120202620413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">
VGG特点及训练层级</p> <ol><li>VGG全部使用3<em>3卷积核、2</em>2池化核，不断加深网络结构来提升性能。</li> <li>A到E网络变深，参数量没有增长很多，参数量主要在3个全连接层。</li> <li>训练比较耗时的依然是卷积层，因计算量比较大。由于卷积核专注于扩大通道数、池化专注于缩小宽和高，使得模型架构上更深更宽的同时，计算量的增加放缓</li> <li>VGG有5段卷积，每段有2个卷积层，每段尾部用池化来缩小图片尺寸。</li> <li>每段内卷积核数一样，越靠后的段卷积核数越多：64–128–256–512–512。</li> <li>训练阶段的三个全连接替换为三个卷积，测试重用训练时的参数，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入</li></ol> <p><img src="https://img-blog.csdnimg.cn/20201120202755637.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> <p>这里演示训练十次的效果</p> <p><img src="https://img-blog.csdnimg.cn/20201120202834810.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MzYzNzkw,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> <p>学习该模型心得及收获</p> <ol><li>通过这样一个网络模型的搭建，加深了我对vgg13神经网络的认识以及tensorflow使用的熟练度。</li> <li>了解的vgg13 3<em>3卷积核的优点
（1）多个一样的3</em>3的卷积层堆叠非常有用
（2）两个3<em>3的卷积层串联相当于1个5</em>5的卷积层，即一个像素会跟周围5<em>5的像素产生关联，感受野大小为5</em>5。
（3）三个3<em>3的卷积层串联相当于1个7</em>7的卷积层，但3个串联的3*3的卷积层有更少的参数量，有更多的非线性变换（3次ReLU激活函数），使得CNN对特征的学习能力更强。</li> <li>卷积的目的及意义：利用数据集去纠正网络中的参数，让相同或者相近的输入在一定误差的影响下依旧可以输出正确的值。通过卷积神经网络，我们可以使得参数的个数和参数的表达能力达到了一个平衡，即参数个数最小化少，但表达力度会最大化。</li> <li>学习到了池化的一些概念和思想：通过max-pooling池化方法减少FeatureMap中不重要的样本，把原图模糊缩减至原来的1/4。通过padding填充使它的尺寸恢复到原来的尺寸。</li></ol> <h2 id="附录-源代码"><a href="#附录-源代码" class="header-anchor">#</a> 附录（源代码）</h2> <div class="language-cpp extra-class"><pre class="language-cpp"><code><span class="token keyword">import</span> <span class="token module">tensorflow</span> as tf
from tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> <span class="token module">layers</span><span class="token punctuation">,</span> optimizers<span class="token punctuation">,</span> datasets<span class="token punctuation">,</span> Sequential
<span class="token keyword">import</span> <span class="token module">os</span>
# 程序运行时系统打印的信息
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token char">'1'</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token char">'TF_CPP_MIN_LOG_LEVEL'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token char">'2'</span>  # 显示warning和error
# 为了使所有ops生成的随机序列在会话中可重复，可以设置一个图级种子<span class="token operator">:</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">set_seed</span><span class="token punctuation">(</span><span class="token number">2345</span><span class="token punctuation">)</span>

conv_layers <span class="token operator">=</span> <span class="token punctuation">[</span> # <span class="token number">5</span> units of conv <span class="token operator">+</span> max pooling
    <span class="token macro property"><span class="token directive-hash">#</span><span class="token expression">Please build vgg13 network according to de demonstration in readme file<span class="token punctuation">,</span> bellow is a instance <span class="token keyword">for</span> unit <span class="token number">1</span></span></span>
    <span class="token macro property"><span class="token directive-hash">#</span><span class="token expression">Please complete other parts<span class="token punctuation">.</span> <span class="token punctuation">(</span>unit <span class="token number">2</span> to unit <span class="token number">5</span><span class="token punctuation">)</span></span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">vgg</span><span class="token expression"><span class="token number">13</span> <span class="token number">13</span>层指的是<span class="token number">10</span>层卷积层和<span class="token number">3</span>层全连接层</span></span>
    # 一共<span class="token number">5</span>个单元的卷积层和池化层，每个单元<span class="token number">2</span>个卷积层和一个池化层

    # 卷积层的filter设置越来越高，将高层的特征传给全连接层用来训练模型
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">filter</span> <span class="token expression">整数，输出空间的维数<span class="token punctuation">(</span>即在“卷积”中输出滤波器的数量<span class="token punctuation">)</span>。</span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">kernel</span><span class="token expression">_size一个整数或<span class="token number">2</span>个整数的元组<span class="token operator">/</span>列表，指定二维卷积窗口的高度和宽度。</span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">padding</span> <span class="token expression">填充 有效或相同（不区分大小写）</span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">activation</span> <span class="token expression">激活函数 这个函数的作用是计算激活函数 relu，即 <span class="token function">max</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>。将大于<span class="token number">0</span>的保持不变，小于<span class="token number">0</span>的数置为<span class="token number">0</span>。</span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Maxpool是取一个区域内的最大值</span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">MaxPool2D 最大池化 output_shape <span class="token operator">=</span> <span class="token punctuation">(</span>input_shape <span class="token operator">-</span> pool_size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> strides    池化核尺寸 池化窗口的移动步长 边缘<span class="token number">0</span>填充</span></span>

    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">unit</span> <span class="token expression"><span class="token number">1</span></span></span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">MaxPool2D</span><span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token char">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">unit</span> <span class="token expression"><span class="token number">2</span></span></span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">MaxPool2D</span><span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token char">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">unit</span> <span class="token expression"><span class="token number">3</span></span></span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">MaxPool2D</span><span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token char">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">unit</span> <span class="token expression"><span class="token number">4</span></span></span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">MaxPool2D</span><span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token char">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">unit</span> <span class="token expression"><span class="token number">5</span></span></span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">Conv2D</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&quot;same&quot;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span><span class="token function">MaxPool2D</span><span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token char">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

<span class="token punctuation">]</span>


def <span class="token function">preprocess</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token operator">:</span>
    # <span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">~</span><span class="token number">1</span><span class="token punctuation">]</span>
    # 张量数据类型转换
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">cast</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.</span>  # 归一化
    y <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">cast</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>  # 把numpy数据转为Tensor
    <span class="token keyword">return</span> x<span class="token punctuation">,</span> y

# 数据自动下载加载
<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> datasets<span class="token punctuation">.</span>cifar100<span class="token punctuation">.</span><span class="token function">load_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">squeeze</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  # 返回一个张量，这个张量是将原始input中所有维度为<span class="token number">1</span>的那些维都删掉的结果
y_test <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">squeeze</span><span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

# 数据处理
train_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span><span class="token function">from_tensor_slices</span><span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span> # 加载数据
train_db <span class="token operator">=</span> train_db<span class="token punctuation">.</span><span class="token function">shuffle</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>preprocess<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">batch</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span> # 打乱数据  预处理函数 一次放入<span class="token number">128</span>个数据

test_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span><span class="token function">from_tensor_slices</span><span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_db <span class="token operator">=</span> test_db<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>preprocess<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">batch</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span>
# 取出一个sample查看 每个样本数据的尺寸，标签的尺寸，最大值最小值
sample <span class="token operator">=</span> <span class="token function">next</span><span class="token punctuation">(</span><span class="token function">iter</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token char">'sample:'</span><span class="token punctuation">,</span> sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> sample<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span>
      tf<span class="token punctuation">.</span><span class="token function">reduce_min</span><span class="token punctuation">(</span>sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span><span class="token function">reduce_max</span><span class="token punctuation">(</span>sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


def <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>

    # <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span>
    conv_net <span class="token operator">=</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>conv_layers<span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Please add your code in blank</span></span>
    # 全连接层
    fc_net <span class="token operator">=</span> <span class="token function">Sequential</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
        layers<span class="token punctuation">.</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span> # <span class="token operator">--</span><span class="token operator">-</span>隐层
        layers<span class="token punctuation">.</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span> # <span class="token operator">--</span><span class="token operator">-</span>隐层
        layers<span class="token punctuation">.</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> # 输出层 you can <span class="token keyword">try</span> other activation function to evaluate <span class="token operator">and</span> compare
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Please add your code in blank</span></span>
    # 卷积层和池化层
    conv_net<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  # <span class="token operator">--</span><span class="token operator">-</span>
    fc_net<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   # <span class="token operator">--</span><span class="token operator">-</span>
    # 设置优化器，优化学习率
    optimizer <span class="token operator">=</span> optimizers<span class="token punctuation">.</span><span class="token function">Adam</span><span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span>

    # <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>
    # #每个层键的参数变量结合起来
    variables <span class="token operator">=</span> conv_net<span class="token punctuation">.</span>trainable_variables <span class="token operator">+</span> fc_net<span class="token punctuation">.</span>trainable_variables
    # 训练
    <span class="token keyword">for</span> epoch in <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token operator">:</span>

        <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> in <span class="token function">enumerate</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token operator">:</span>

            with tf<span class="token punctuation">.</span><span class="token function">GradientTape</span><span class="token punctuation">(</span><span class="token punctuation">)</span> as tape<span class="token operator">:</span>
                # 卷积层和池化层
                # <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span>
                out <span class="token operator">=</span> <span class="token function">conv_net</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
                <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">flatten</span><span class="token expression"><span class="token punctuation">,</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span></span></span>
                # 展平
                out <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>out<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                # 全连接层
                # <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span>
                # 我们将展平后的结果传递到全连接层网络fc_net得到预测值
                # 走完卷积层，池化层，全连接层得到输出值
                logits <span class="token operator">=</span> <span class="token function">fc_net</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span>

                # 求解Loss值<span class="token punctuation">,</span>需要将y的尺寸补齐到logits的尺寸
                # <span class="token punctuation">[</span>b<span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>b<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span>
                y_onehot <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">one_hot</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>  # 独热 表示各自的概率分布
                <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">compute</span> <span class="token expression">loss</span></span>
                # 交叉熵误差
                # 函数在计算损失函数前，会先内部调用 Softmax函数
                # 多分类的对数损失函数 针对于独热化标签的多分类问题 真实值 预测值（输出层的输出）
                loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>losses<span class="token punctuation">.</span><span class="token function">categorical_crossentropy</span><span class="token punctuation">(</span>y_onehot<span class="token punctuation">,</span> logits<span class="token punctuation">,</span> from_logits<span class="token operator">=</span>True<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reduce_mean</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span> # 计算平均交叉熵损失
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Please add your code in blank</span></span>
            # 反向传播，对所有的层间参数进行求导
            grads <span class="token operator">=</span> tape<span class="token punctuation">.</span><span class="token function">gradient</span><span class="token punctuation">(</span>loss<span class="token punctuation">,</span> variables<span class="token punctuation">)</span>   # <span class="token operator">--</span><span class="token operator">-</span>
            # 更新梯度
            optimizer<span class="token punctuation">.</span><span class="token function">apply_gradients</span><span class="token punctuation">(</span><span class="token function">zip</span><span class="token punctuation">(</span>grads<span class="token punctuation">,</span> variables<span class="token punctuation">)</span><span class="token punctuation">)</span>  # <span class="token operator">--</span><span class="token operator">-</span>
            # 每<span class="token number">100</span>个样本打印一次结果
            <span class="token keyword">if</span> step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token operator">:</span>
                <span class="token function">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> step<span class="token punctuation">,</span> <span class="token char">'loss:'</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>



        total_num <span class="token operator">=</span> <span class="token number">0</span>
        total_correct <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y in test_db<span class="token operator">:</span>

            out <span class="token operator">=</span> <span class="token function">conv_net</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            out <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>out<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            logits <span class="token operator">=</span> <span class="token function">fc_net</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span>
            <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">softmax</span><span class="token expression">转换成概率 将logistic的预测二分类的概率的问题推广到了n分类的概率的问题</span></span>
            prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span><span class="token function">softmax</span><span class="token punctuation">(</span>logits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  # 输出向量是概率，该样本属于各个类的概率
            # 选择概率最大的作为预测值
            pred <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">argmax</span><span class="token punctuation">(</span>prob<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            pred <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">cast</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
            # 计算正确预测的数量
            correct <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">cast</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token function">equal</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
            correct <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token function">reduce_sum</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>

            total_num <span class="token operator">+=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            total_correct <span class="token operator">+=</span> <span class="token keyword">int</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>
        # 计算正确率
        acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_num
        <span class="token function">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> <span class="token char">'acc:'</span><span class="token punctuation">,</span> acc<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token char">'__main__'</span><span class="token operator">:</span>
    <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/Blog/Blog/Deep-learning/blog2/" class="prev">
        手写体数字识别(Hand-written digits recognition)
      </a></span> <span class="next"><a href="/Blog/Blog/Others/blog1/">
        如何每次随机出不同的数-Math.random()
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/Blog/assets/js/app.05fbaaaf.js" defer></script><script src="/Blog/assets/js/2.733019b2.js" defer></script><script src="/Blog/assets/js/10.1c5858b8.js" defer></script>
  </body>
</html>
